{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a competative supervised model for wild type PETase activity at low pH\n",
    "\n",
    "We show in a seperate paper [TODO]() that supervised models should be used for predicting PETase activity at unique conditions (eg. low pH) once some assay labeled data is available, and this outperforms HMMs. Here we create models that:\n",
    "1. Take in embeddings as input, explore over: Aligned OHE, ES|M2, SaProt, MSATransformer\n",
    "2. Use linear vs non-linear models: Linear regression, Random Forest\n",
    "\n",
    "Hyperperameter optimization is conducted over the models for each input type.\n",
    "\n",
    "Save the final model, which can be loaded like any other sklearn model if AIDE is installed.\n",
    "\n",
    "eg. `model=joblib.load('model.pkl')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_validate\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import loguniform, spearmanr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import aide_predict as ap\n",
    "from aide_predict.utils.data_structures.structures import StructureMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and prepare data\n",
    "\n",
    "We need to get:\n",
    "1. The sequences and labels\n",
    "2. Assign their structures (for SaProt Embedding)\n",
    "3. Get and MSA of known PETases (for baseline HMMscore and MSA transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = os.path.join('.', 'data', 'p740')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(RAW_DATA_DIR, 'label_data.csv'), index_col=0).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['activity_at_5.5_40_cryPow'])\n",
    "# drop rows with non canonical AAs - these were not predicted properly by AF\n",
    "X = ap.ProteinSequences.from_dict(df['sequence'].to_dict())\n",
    "has_non_canonical = [x.has_non_canonical for x in X]\n",
    "df = df[~np.array(has_non_canonical)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ap.ProteinSequences.from_dict(df['sequence'].to_dict())\n",
    "y = df['activity_at_5.5_40_cryPow'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y, bw_adjust=0.5)\n",
    "plt.xlabel('Activity at 5.5 pH, 40Â°C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the structures - Needed for SaProt embedding\n",
    "mapper = StructureMapper(os.path.join(RAW_DATA_DIR, 'structures'))\n",
    "mapper.assign_structures(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Homolog MSA (for MSA transformer)\n",
    "\n",
    "Compute weights so that MSA transformer can sample it properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = ap.ProteinSequences.from_fasta(os.path.join(RAW_DATA_DIR, 'D1-Scraped-513.mfa'))\n",
    "msa.aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa.width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cv\n",
    "cv_obj = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics to measure\n",
    "# marks magnitude of error eg R2, also score AUROC to see if the model can classify active or not\n",
    "scoring = {\n",
    "    'spearman': lambda est, X, y: spearmanr(y, est.predict(X))[0],\n",
    "    'roc_auc': lambda est, X, y: roc_auc_score(y > 0.001, est.predict(X))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pipeline(embedder, model, pca: bool=False):\n",
    "    if not pca:\n",
    "        return Pipeline([\n",
    "            ('embedder', embedder),\n",
    "            ('var', VarianceThreshold()),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "    else:\n",
    "        return Pipeline([\n",
    "            ('embedder', embedder),\n",
    "            ('var', VarianceThreshold()),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=0.95)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "def evaluate_pipeline_with_hyperopt(embedder, model_info, n_iter=10):\n",
    "    \"\"\"Run hyperparameter optimization on a pipeline with a given embedder and model\n",
    "    \n",
    "    Params:\n",
    "    embedder: Embedder object eg ap.BaseProteinModel\n",
    "    model_info: dict with keys:\n",
    "        'model': sklearn model object\n",
    "        'param_distributions': dict of hyperparameter distributions for RandomizedSearchCV\n",
    "    \"\"\"\n",
    "    pipeline = construct_pipeline(embedder, model_info['model'])\n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=model_info['param_dist'],\n",
    "        n_iter=n_iter,\n",
    "        cv=cv_obj,\n",
    "        scoring=scoring,\n",
    "        refit='spearman',\n",
    "        n_jobs=1)\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    best_params = random_search.best_params_\n",
    "    cv_scores = cross_validate(pipeline.set_params(**best_params), X, y, cv=cv_obj, scoring=scoring)\n",
    "    return best_params, cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline model: HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = ap.HMMWrapper()\n",
    "hmm.fit(msa)\n",
    "\n",
    "baseline_scores = {\n",
    "    k: v(hmm, X, y) for k, v in scoring.items()\n",
    "}\n",
    "print('Baseline scores:', baseline_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised learning: Define embedders, models, and hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedders = {\n",
    "    'ESM2': ap.ESM2Embedding(\n",
    "        metadata_folder='esm2_embeddings', model_checkpoint='esm2_t33_650M_UR50D', device='mps', pool='mean'),\n",
    "    'SaProt': ap.SaProtEmbedding(metadata_folder='saprot_embeddings', device='mps', pool='mean'),\n",
    "    'MSATransformer': ap.MSATransformerEmbedding(\n",
    "        metadata_folder='msa_embeddings', device='mps', pool='mean',\n",
    "        n_msa_seqs=32\n",
    "    ),\n",
    "    'AlignedOneHot': ap.OneHotAlignedEmbedding(\n",
    "        metadata_folder='onehot_embeddings')\n",
    "}\n",
    "# fit the models that have fixed fitting over folds\n",
    "embedders['ESM2'].fit([])\n",
    "embedders['SaProt'].fit([])\n",
    "embedders['MSATransformer'].fit(msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'ElasticNet': {\n",
    "        'model': ElasticNet(),\n",
    "        'param_dist': {\n",
    "            'model__alpha': loguniform(1e-5, 1e2),\n",
    "            'model__l1_ratio': np.linspace(0, 1, 11)\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestRegressor(n_estimators=10),\n",
    "        'param_dist': {\n",
    "            'model__max_depth': [None, 10, 100],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__min_samples_leaf': [1, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and evaluate models with hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "if not os.path.exists('search_results.pkl'):\n",
    "    results = {}\n",
    "else:\n",
    "    results = joblib.load('search_results.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedder_name, embedder in embedders.items():\n",
    "    for model_name, model_info in models.items():\n",
    "        if f'{embedder_name}_{model_name}' in results:\n",
    "            print(f\"Skipping {embedder_name} with {model_name}...\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Evaluating {embedder_name} with {model_name}...\")\n",
    "        best_params, scores = evaluate_pipeline_with_hyperopt(embedder, model_info, n_iter=200)\n",
    "        results[f'{embedder_name}_{model_name}'] = {\n",
    "            'embedder': embedder_name,\n",
    "            'model': model_name,\n",
    "            'best_params': best_params,\n",
    "            'spearman': scores['test_spearman'],\n",
    "            'roc_auc': scores['test_roc_auc']\n",
    "        }\n",
    "        joblib.dump(results, 'search_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to long\n",
    "df_list = []\n",
    "for item in results.values():\n",
    "    for i in range(5):  # Assuming 5 values for each metric\n",
    "        df_list.append({\n",
    "            'embedder': item['embedder'],\n",
    "            'model': item['model'],\n",
    "            'spearman': item['spearman'][i],\n",
    "            'roc_auc': item['roc_auc'][i]\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(df_list)\n",
    "\n",
    "# Melt the DataFrame to create a column for the metric type\n",
    "df_melted = pd.melt(df, id_vars=['embedder', 'model'], var_name='metric', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Create the faceted plot\n",
    "g = sns.catplot(\n",
    "    data=df_melted,\n",
    "    kind=\"bar\",\n",
    "    x=\"model\",\n",
    "    y=\"value\",\n",
    "    hue=\"metric\",\n",
    "    col=\"embedder\",\n",
    "    height=4,\n",
    "    aspect=1.0,\n",
    "    palette=\"Set2\",\n",
    "    col_wrap=4,\n",
    "    ci=\"sd\",\n",
    "    legend=True  # We'll add the legend manually\n",
    ")\n",
    "# remove legend from seaborn\n",
    "g._legend.remove()\n",
    "# add baselines of the same color as the bars\n",
    "for ax in g.axes.flat:\n",
    "    for i, metric in enumerate(['spearman', 'roc_auc']):\n",
    "        ax.axhline(baseline_scores[metric], color=sns.color_palette(\"Set2\")[i], linestyle='--', label=f'Baseline {metric}')\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(-1.1, -0.28), ncol=4)\n",
    "# Customize the plot\n",
    "g.set_axis_labels(\"Model\", \"Value\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig('p740_model_comparison.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train final model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = df.groupby(['embedder', 'model']).mean().sort_values('roc_auc', ascending=False).iloc[0]\n",
    "best_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = construct_pipeline(embedders[best_row.name[0]], models[best_row.name[1]]['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_pipeline, 'p740_best_pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
